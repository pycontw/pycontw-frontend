__NUXT_JSONP__("/zh-hant/conference/talk/342", (function(a,b){b.id=342;b.begin_time="2025-09-07T02:50:00Z";b.end_time="2025-09-07T03:35:00Z";b.is_remote=false;b.location="5-r1";b.youtube_id=a;b.title="How to integrate python tools with Apache Iceberg to build ETLT pipeline on Shift-Left Architecture";b.category="APPL";b.language="ZHEN";b.python_level="INTERMEDIATE";b.recording_policy=true;b.abstract="This session will begin by exploring why the industry is increasingly moving toward the lakehouse architecture, highlighting the core challenges it addresses in modern data processing. Using this as a foundation, we will introduce the ETLT pattern and compare two architectural approaches: the Shift-Left Architecture and the Medallion Architecture, outlining their key differences and applicable scenarios.\r\n\r\nWe will also cover the essential technologies used throughout the data pipeline, including Kafka, PySpark, Trino, and DBT for Left-Shit Architecture. For Python developers, we’ll demonstrate how to efficiently read and interact with Iceberg-formatted data, showcasing code snippets and configuration examples to provide practical guidance.\r\n\r\nThe talk will conclude with real-world best practices to help data professionals evaluate whether this architecture fits their use cases and how it can be leveraged to improve existing data workflows.";b.detailed_description="This session introduces how the Shift-Left Architecture, combined with the ETLT pattern, addresses the limitations of traditional data pipelines. We’ll explore how Apache Iceberg, as an open table format, enables features like schema evolution and time-travel, and why lakehouse architecture is becoming the foundation for scalable, maintainable data systems. Through practical examples, we’ll demonstrate how to build an end-to-end pipeline using Kafka, PySpark, Trino, and DBT, with live code snippets and configurations. The session also compares Shift-Left and Medallion Architectures, offering clear guidance on when to adopt each. Attendees will leave with actionable insights and best practices for modernizing data workflows using Python-native tools.\r\n\r\n**Session Outline**\r\n1. Introduction\r\n    * Overview of modern data architecture & ETLT pattern & challenge.\r\n    * Why do we need lakehouse as our data storage?\r\n\r\n2. The difference of Shift-Left Architecture & Medallion Architecture\r\n\r\n3. Implementation Techniques & Code Patterns\r\n    * Core concepts and architecture of Apache Iceberg\r\n        * Open Table format features.\r\n        * Version control and time travel.\r\n        * Schema evolution & Hidden partition.\r\n    * Overview of related data integration tools\r\n        * PySpark integration points & code snippet with Iceberg.\r\n        * Query iceberg from Trino engine & related configuration.\r\n        * Integrate Trino & DBT to achieve ELT process and data management.\r\n        * How to query iceberg data from general python implementation.\r\n    * Quick Use Case Application\r\n\r\n4. Conclusion & Q&A\r\n    * Key takeaways and best practices summary\r\n    * Future development directions and trends\r\n    * Recommended resources\r\n\r\n**Reference**\r\n* [What is Shift Left?](https:\u002F\u002Fwww.confluent.io\u002Flearn\u002Fwhat-is-shift-left\u002F)\r\n* [Shift left to write data once, read as tables or streams](https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=FiZmyl1Npg0&t=858s)\r\n* [Shift Left: The Key to Faster, Smarter, and More Efficient Data Pipelines](https:\u002F\u002Fblog.det.life\u002Fshift-left-the-key-to-faster-smarter-and-more-efficient-data-pipelines-c3c7e8f466a4)\r\n* [Apache IceBerg](https:\u002F\u002Ficeberg.apache.org)\r\n* [Introduction to the Iceberg Data Lakehouse](https:\u002F\u002Fwww.dremio.com\u002Fblog\u002Ficeberg-data-lakehouse\u002F)\r\n* [Apache Iceberg and PySpark](https:\u002F\u002Fkarlchris.github.io\u002Fdata-engineering\u002Fprojects\u002Fspark-iceberg\u002F#installing-apache-iceberg)\r\n* [Introduction to Apache Iceberg In Trino](https:\u002F\u002Fwww.starburst.io\u002Fblog\u002Fintroduction-to-apache-iceberg-in-trino\u002F)\r\n* [First dbt-trino data pipeline](https:\u002F\u002Fwww.starburst.io\u002Fblog\u002Flakehouse-data-pipeline-dbt-trino\u002Finstall-dbt\u002F)";b.slide_link=a;b.slido_embed_link="https:\u002F\u002Fapp.sli.do\u002Fevent\u002FaNa5FUTpqtR4jPChC6qmrs";b.hackmd_embed_link=a;b.speakers=[{thumbnail_url:"https:\u002F\u002Ftw.pycon.org\u002Fprs\u002Fmedia\u002Fcache\u002F5e\u002F45\u002F5e450bb916fc55fa20ff8ac3d0b1fa05.jpg",name:"蘇揮原 Mars Su",github_profile_url:"https:\u002F\u002Fgithub.com\u002Fhueiyuan",twitter_profile_url:a,facebook_profile_url:"https:\u002F\u002Fwww.facebook.com\u002Fprofile.php?id=100000271047129",bio:"A Staff Data Engineer in TrendMicro. With over 7 years of experience in data engineering and machine learning. Mainly includes NLP, LLM model training and application, and streaming or batch ETL, ELT related data architecture design and development. I am willing to pursue new knowledge and skill and share it so that I can make greater contributions in Big Data and ML field in the future."}];b.event_type="talk";return {data:[{speechData:b}],fetch:{},mutations:[["setSpeechData",b]]}}("",{})));