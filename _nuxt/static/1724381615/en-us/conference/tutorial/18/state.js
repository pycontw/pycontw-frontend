window.__NUXT__=(function(a,b,c,d){return {staticAssetsBase:"\u002Fpycontw-frontend\u002F_nuxt\u002Fstatic\u002F1724381615",layout:"default",error:d,state:{sponsorsData:[],jobsData:[],schedulesData:[],keynotesData:[],youtubeInfo:[],speechesData:[],speechData:{id:18,begin_time:"2024-09-21T05:20:00Z",end_time:"2024-09-21T06:45:00Z",is_remote:c,location:"1-r3",registration_link:b,youtube_id:b,title:"探索大型語言模型實戰方法：透過 Python 將 LLM 服務化、RAG 知識管理、Fine-Tune 模型在 AI 專案中",category:"NLP",language:"ZHEN",python_level:"INTERMEDIATE",recording_policy:a,abstract:"自 2022 年底起，隨著生成式 AI 技術的快速進展，大型語言模型（ LLMs ）已成為業界與學術界的焦點。在這次的演講中，我將以最淺顯易懂的方式，帶領大家深入了解大型語言模型在實務應用中的關鍵技術與策略，涵蓋 RAG 知識管理、 LLM 的服務化、模型微調（Fine-Tuning）和導入 DevOps 在 AI 專案這四大領域。\r\n\r\n首先，我們將探討 RAG 如何結合檢索技術，提升 LLMs 的專業知識理解能力，使模型能有效處理大量資料並提供更精準的解答。\r\n\r\n接著，我們將介紹並分析 LLM 轉化為服務（ LLM as a Service ）的重要性，探討如何將這些強大的模型轉化為便於接入與使用的服務，使更多企業與開發者能運用這些尖端技術進行創新與問題解決。\r\n\r\n再來，我們將介紹模型微調的實踐方法，說明如何根據具體應用場景對模型進行調整和優化，以滿足不同需求。\r\n\r\n最後，我會提供 LLM for DevOps 的流程，讓大家了解在上線 LLM 專案時的流程與應注意的事項。\r\n\r\n透過以上內容，聽眾將能以最易理解的方式了解 LLMs 的實戰應用，為後續深入探索 LLMs 的應用奠定基礎，進而為未來公司專案的技術創新與應用做好準備。\r\n\r\n注意事項：\r\n1. 本次活動將會使用 Google Colab 進行實作，請提前準備帳號。",detailed_description:"* LLMs (大型語言模型) 介紹：\r\n大型語言模型（Large Language Models，簡稱LLMs）是一種使用深度學習技術訓練，且能夠處理、理解和生成人類自然語言的模型。這些模型通常需要大量的計算資源和大規模的數據集來進行訓練，以便捕捉語言的複雜性和多樣性。\r\nLLMs 能夠進行各種語言任務，包括但不限於文本生成、翻譯、摘要、問答和情感分析。這些模型學習語言的細微差異和語境，能夠根據給定的輸入（我們稱之為 Prompt）生成相關且連貫的解答與內容。\r\n\r\n* RAG (Retrieval-Augmented Generation) ：\r\nRAG，即檢索增強生成技術，是一種結合了檢索（Retrieval）和生成（Generation）的方法，用於提升語言模型的效能。具體來說，RAG 先從大量數據中搜尋出相關的知識內容，再基於這些訊息進行內容生成工作。這種方法特別適用於需要廣泛背景知識來回答問題或生成文本的場景。例如，當你問一個特定領域的問題時，RAG 能夠先找到相關的文獻或數據，然後再基於這些資料生成答案，從而提高回答的準確性和可靠性。\r\n\r\n* Sentence-transformer：\r\nSentence-Transformer 是一種基於深度學習的模型框架，專門用於生成文本向量（sentence embeddings）。這些句向量可用於各種自然語言處理（NLP）任務，如語句相似度比對、文本分類和資訊檢索。Sentence-Transformer 不僅提高了處理效率，也通過精確的句向量增強了模型在各種 NLP 任務上的表現。它是一個對於希望在實際應用中使用句向量的研究者和開發者來說非常有用的工具。\r\n\r\n* pgvector：\r\npgvector 是一款開源的 PostgreSQL 擴展，專門用於高效處理和搜索向量數據，例如機器學習模型產生的向量。這種類型的數據常用於推薦系統、圖像識別和自然語言處理等領域。pgvector 向量相似性搜索、高效存儲和索引和易於整合的特性，提供了一個方便的方式來擴展傳統的關聯式資料庫，以處理現代 AI 應用中的大量向量數據。\r\n\r\n* Ollama：\r\nOllama 是一個開源軟體，讓使用者可以在自己的硬體上運行、創建和分享大型語言模型服務。這個平台適合希望在地端運行模型的使用者，因為它不僅可以保護隱私，還允許用戶透過命令行介面輕鬆地設置和互動。Ollama 支援包括 Llama 2 和 Mistral 等多種模型，並提供彈性的客製化選項，例如從 gguf 格式導入模型並設置參數等。",slide_link:b,slido_embed_link:b,hackmd_embed_link:b,speakers:[{thumbnail_url:"https:\u002F\u002Ftw.pycon.org\u002Fprs\u002Fmedia\u002Fcache\u002F75\u002Fa9\u002F75a9eae9c900e1eea4edc13e11b46970.jpg",name:"劉育維",github_profile_url:"https:\u002F\u002Fgithub.com\u002FLiuYuWei",twitter_profile_url:b,facebook_profile_url:"https:\u002F\u002Fwww.facebook.com\u002Fsimonliuyuwei",bio:"大家好，我是 Simon 劉育維，過去曾擔任過電信業的資深工程師 和 在軟體業擔任 MLOps 客戶技術成功工程師，幫助各大知名企業進行機器學習、深度學習、大型語言模型等人工智慧議題進行人工智慧架構規劃的討論，目前在 Medium 上已經公開超過 60 篇技術文章，我希望能夠嘗試使用 AI 做應用，幫助客戶用 AI 解決痛點。"}],event_type:"tutorial"},relatedData:[],configs:{conferenceName:"PyCon TW",conferenceYear:"2024",conferenceDate:"2024-09-21",showAboutStaffPage:a,showConferencePage:a,showEventOverviewPage:a,showEventsPage:a,showIndexSecondaryBtn:a,showIndexSponsorSection:a,showProposalSystemPage:a,showRegistrationPage:a,showSchedulePage:c,showSpeakingPage:c,showSponsorPage:a,showVenuePage:a,aboutHideItems:["apacCommunity"],conferenceHideItems:["panelDiscussion"],eventsHideItems:[],registrationHideItems:[],venueHideItems:[]},i18n:{routeParams:{}}},serverRendered:a,routePath:"\u002Fen-us\u002Fconference\u002Ftutorial\u002F18",config:{gtm:{id:"GTM-TNZ39PD"},_app:{basePath:"\u002Fpycontw-frontend\u002F",assetsPath:"\u002Fpycontw-frontend\u002F_nuxt\u002F",cdnURL:d}}}}(true,"",false,null));