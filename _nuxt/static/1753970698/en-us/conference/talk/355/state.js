window.__NUXT__=(function(a,b,c,d){return {staticAssetsBase:"\u002Fpycontw-frontend\u002F_nuxt\u002Fstatic\u002F1753970698",layout:"default",error:d,state:{sponsorsData:[],jobsData:[],schedulesData:[],keynotesData:[],youtubeInfo:[],speechesData:[],speechData:{id:355,begin_time:"2025-09-06T02:50:00Z",end_time:"2025-09-06T03:20:00Z",is_remote:c,location:"4-r0",youtube_id:b,title:"Text-Driven Image Cropping with Deep Learning and Genetic Algorithm",category:"ML",language:"ZHEN",python_level:"INTERMEDIATE",recording_policy:a,abstract:"分享我個人的 side project \"Text2Focus\"，一個能根據文字描述，自動裁剪圖片中關鍵區域的工具。它使用 Saliency Detection 以及 Zero Shot Object Detection 偵測圖片的關鍵區域，有鑑於所謂的 \"好\" 剪裁不容易使用單一目標函數來表示，該工具使用多目標優化 Genetic Algorithm 在數個目標函數中提供 Pareto Front Optimization set，來滿足使用者的需求。",detailed_description:"Text2Focus 是一個可以根據你給的文字描述，幫你自動裁剪圖片的工具。\r\n\r\n## 1. 功能\r\n\r\n![demo.gif](https:\u002F\u002Fraw.githubusercontent.com\u002Favengerandy\u002FText2Focus\u002Fmaster\u002Fimg\u002Fdemo.gif)\r\n\r\n主要的功能就是根據用戶提供的文字描述（「人臉」、「狗」）來裁剪圖片，它會通過兩步來完成裁剪:\r\n* 計算圖片的重點區域在哪些位置。\r\n* 根據重點區域的分布，自動裁切圖片。\r\n\r\n## 2. 實作\r\n\r\n### 計算重點區域\r\n\r\n重點區域由兩個兩個模型一同計算:\r\n\r\n* Pyramid Feature Attention Network \\[1\\]：這個模型負責根據圖片計算出前景，做為可能的重點區域。\r\n* OWLv2 \\[2\\]：這個模型負責根據圖片以及用戶文字做 Object Detection，抓出用戶認為是重點的物體。\r\n\r\n最終結合這兩個模型的輸出就是重點區域了。\r\n\r\n### 自動裁切\r\n\r\n一個 \"好\" 的裁切是不容易被單一定義的，所以 Text2Focus 使用三種目標函數:\r\n\r\n* 裁切區域有越多重點區域越好。\r\n* 裁切區域內的重點比例要高。\r\n* 在邊緣被裁切到的重點區域越少越好。\r\n\r\n並使用簡易版的多目標遺傳演算法 \\[3\\]，提供 Pareto Front Optimization set 讓用戶挑選適合的裁切結果。\r\n\r\n## 3. 參考資料\r\n\r\n\\[1\\] Sairajk. PyTorch Pyramid Feature Attention Network for Saliency Detection. GitHub, n.d., https:\u002F\u002Fgithub.com\u002Fsairajk\u002FPyTorch-Pyramid-Feature-Attention-Network-for-Saliency-Detection.\r\n\\[2\\] Google. OWL-ViT 2 Base Patch 16 Ensemble. Hugging Face, n.d., https:\u002F\u002Fhuggingface.co\u002Fgoogle\u002Fowlv2-base-patch16-ensemble.\r\n\\[3\\] Deb, Kalyanmoy, et al. \"A fast and elitist multiobjective genetic algorithm: NSGA-II.\" IEEE transactions on evolutionary computation 6.2 (2002): 182-197.\r\n\r\n## 完整資料可以參考該工具 [Text2Focus github 倉庫](https:\u002F\u002Fgithub.com\u002Favengerandy\u002FText2Focus)",slide_link:b,slido_embed_link:b,hackmd_embed_link:b,speakers:[{thumbnail_url:"https:\u002F\u002Ftw.pycon.org\u002Fprs\u002Fmedia\u002Fcache\u002F57\u002F06\u002F570696276d815fb22951c8e9362a9848.jpg",name:"Mazer",github_profile_url:"https:\u002F\u002Fgithub.com\u002Favengerandy",twitter_profile_url:b,facebook_profile_url:b,bio:"I am Mazer (Ting-Yu Chen), not a good enough software engineer, but someone who enjoys moments of insight during the research process. \"The sky and the cosmos are one.\" — The Choir, Bloodborne."}],event_type:"talk"},relatedData:[],reviewerData:[],configs:{conferenceName:"PyCon TW",conferenceYear:"2025",conferenceDate:"2025-09-06",showAboutStaffPage:c,showConferencePage:a,showSchedulePage:a,showEventOverviewPage:a,showEventsPage:a,showIndexSecondaryBtn:a,showIndexSponsorSection:c,showProposalSystemPage:a,showRegistrationPage:a,showSpeakingPage:a,showSponsorPage:a,showVenuePage:c,aboutHideItems:["apacCommunity"],conferenceHideItems:[],eventsHideItems:["jobs"],registrationHideItems:[],venueHideItems:["venueInfo","accommodation"]},i18n:{routeParams:{}}},serverRendered:a,routePath:"\u002Fen-us\u002Fconference\u002Ftalk\u002F355",config:{http:{browserBaseURL:"https:\u002F\u002Fstaging.pycon.tw\u002Fprs"},gtm:{id:"GTM-TNZ39PD"},_app:{basePath:"\u002Fpycontw-frontend\u002F",assetsPath:"\u002Fpycontw-frontend\u002F_nuxt\u002F",cdnURL:d}}}}(true,"",false,null));